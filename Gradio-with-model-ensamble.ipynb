{"cells":[{"cell_type":"markdown","metadata":{"id":"bPNWkYXylMMF"},"source":["# Image-Classification-For-Cross-Analysis-of-Chest-X-Ray"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":13807,"status":"ok","timestamp":1716255471684,"user":{"displayName":"Nathan Tyler","userId":"01089041167657734180"},"user_tz":360},"id":"7Jj96KdzlMMH"},"outputs":[],"source":["\"\"\"\n","Loads a pretrained CNN model and presents a Gradio app to the user.\n","The user can upload a chest X-Ray image which will be preprocessed similarly\n","to the trained model, then run through the model.\n","A prediction of 1 or more of 14 diagnoses or no diagnosis will be output.\n","This will be followed up with suggested treatment from an OpenAI API.\n","\"\"\"\n","\n","# Standard imports\n","import pandas as pd\n","from pathlib import Path\n","import numpy as np\n","import requests\n","from PIL import Image\n","import tensorflow as tf\n","from pathlib import Path\n","import gradio as gr\n","from gtts import gTTS\n","import random"]},{"cell_type":"markdown","metadata":{},"source":["# Gradio App Ensambling Aleksandar's and Patrick's Models"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":1818,"status":"ok","timestamp":1716255490959,"user":{"displayName":"Nathan Tyler","userId":"01089041167657734180"},"user_tz":360},"id":"pDGPq_FxlMMJ"},"outputs":[{"name":"stderr","output_type":"stream","text":["d:\\Development\\anaconda3\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 12 variables whereas the saved optimizer has 22 variables. \n","  saveable.load_own_variables(weights_store.get(inner_path))\n"]}],"source":["# first lets load our pre-trained models\n","aleksandar_model = tf.keras.models.load_model(Path(\"Resources/detection_model.keras\"))\n","patrick_model =  tf.keras.models.load_model(Path(\"Resources/final_model.keras\"))"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["# Load the CSV file that has list of all images, for random selection\n","df = pd.read_csv(\"Resources/Data_Entry_2017_v2020.csv\")"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[],"source":["# Define the load random function to load any of the images within the dataset (CSV)\n","def load_random(submit):\n","    idx = random.randrange(0, len(df[\"Image Index\"]))\n","    img_name = df[\"Image Index\"].iloc[idx]\n","    img_name = f\"./Images/{img_name}\"\n","    print(img_name)\n","    return img_name\n"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[],"source":["# Make our gradio app compenents dynamic\n","def enable_submit(submit):\n","    return gr.update(interactive=True)\n","\n","def disable_submit(submit):\n","    return gr.update(interactive=False)\n"]},{"cell_type":"code","execution_count":32,"metadata":{"executionInfo":{"elapsed":103,"status":"ok","timestamp":1716257363122,"user":{"displayName":"Nathan Tyler","userId":"01089041167657734180"},"user_tz":360},"id":"DVVgM724lMMK"},"outputs":[],"source":["# Define the function of our model that will process the image and meta data to make a prediction\n","def do_predict(img):\n","    # Process image based on preprocess code and prep to enter into model\n","    img = Image.fromarray(img)\n","    # setup model 1 image\n","    mod1img = img.resize((256, 256))\n","    mod1img = mod1img.convert('RGB')  # Ensure all images are in RGB format\n","    mod1img = np.array(mod1img)\n","    mod1img = mod1img / 255.0 # Normalize to range [0, 1]\n","    mod1img = np.array(mod1img)\n","    mod1img = np.expand_dims(mod1img, axis=0)\n","    # setup model 2 image\n","    mod2img = img.resize((224, 224))\n","    mod2img = mod2img.convert('RGB')  # Ensure all images are in RGB format\n","    mod2img = np.array(mod2img)\n","    mod2img = mod2img / 255.0 # Normalize to range [0, 1]\n","    mod2img = np.array(mod2img)\n","    mod2img = np.expand_dims(mod2img, axis=0)\n","\n","    # make predictions with both models\n","    prediction1 = aleksandar_model.predict(mod1img)\n","    prediction2 = patrick_model.predict(mod2img)\n","    \n","    # take the average of the predictions\n","    prediction = (prediction1[0][0] + prediction2[0][0]) / 2\n","    \n","    # With a poor performing model we wanted a little better breakdown than a simple binary output\n","    # Using two break points on the sigmoid output to add in the ambiguity.\n","    if prediction < 0.50:\n","        output = f\"This model found nothing in the X-ray. Disclaimer: This app should only be used by doctors as a cross reference with standard radiology.\"\n","    else:\n","        output = f\"This model suspects a diagnosis in this X-ray. Human analysis is required to determine the exact diagnosis.\"\n","\n","    # Create a wave file for the Text-to-speach output (hope simulateous connectsion do not cause problems here)\n","    wavobj = gTTS(text=output, lang=\"en\", slow=False)\n","    wavobj.save(\"output.wav\")\n"," \n","    return output, \"output.wav\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":646},"executionInfo":{"elapsed":1261,"status":"ok","timestamp":1716257367053,"user":{"displayName":"Nathan Tyler","userId":"01089041167657734180"},"user_tz":360},"id":"MF5Y7duwlMMK","outputId":"fd4dcb14-2afa-40af-ae3b-aeefd9aede87"},"outputs":[{"name":"stdout","output_type":"stream","text":["Running on local URL:  http://127.0.0.1:7868\n","Running on public URL: https://d1a5467b317cc940f6.gradio.live\n","\n","This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"]},{"data":{"text/html":["<div><iframe src=\"https://d1a5467b317cc940f6.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":[]},"execution_count":33,"metadata":{},"output_type":"execute_result"},{"name":"stdout","output_type":"stream","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 418ms/step\n","./Images/00012012_000.png\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 600ms/step\n","./Images/00018253_060.png\n","./Images/00003523_001.png\n","./Images/00005460_003.png\n","./Images/00000512_002.png\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n","./Images/00019928_000.png\n","./Images/00010620_002.png\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 536ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 508ms/step\n","./Images/00016421_001.png\n","./Images/00013111_024.png\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 567ms/step\n","./Images/00007502_000.png\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 504ms/step\n","./Images/00014900_000.png\n","./Images/00014196_003.png\n","./Images/00010433_008.png\n","./Images/00004808_080.png\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 615ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 599ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 694ms/step\n","./Images/00022526_014.png\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 677ms/step\n","./Images/00010772_002.png\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 464ms/step\n","./Images/00005069_013.png\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 465ms/step\n","./Images/00020725_033.png\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 435ms/step\n","./Images/00021860_009.png\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 448ms/step\n","./Images/00006736_008.png\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 496ms/step\n","./Images/00027415_061.png\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480ms/step\n","./Images/00022985_000.png\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454ms/step\n","./Images/00008655_000.png\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 466ms/step\n","./Images/00016523_002.png\n"]}],"source":["# Create an instance of the Gradio Blocks as a dynamic application\n","\n","with gr.Blocks(theme=\"abidlabs/dracula_revamped\") as app:\n","        title = gr.Markdown(\"# Demo&mdash;Chest X-Ray Cross Analysis\")\n","        rand = gr.Button(value=\"Load Random Image from Dataset.\")\n","        image = gr.Image(label=\"Or Upload Your Own.\", value=\"PIL.Image.Image\", interactive=True)\n","        submit = gr.Button(value=\"Classify Image\", interactive=False)\n","        out_txt = gr.Textbox(lines=3, label=\"Text Prediction\", show_copy_button=True)\n","        out_aud = gr.Audio(autoplay=False, label=\"Audio Prediction\", interactive=False)\n","        image.change(enable_submit, inputs=submit, outputs=submit)\n","        image.clear(disable_submit, inputs=submit, outputs=submit)\n","        rand.click(load_random, inputs=rand, outputs=image)\n","        submit.click(do_predict, inputs=image, outputs=[out_txt, out_aud])\n","# Launch the app\n","app.launch(share=True)"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"down","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":0}
