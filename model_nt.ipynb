{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNqmjMMqJoKkcp6N8iDqnGa"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# 1. Import preprocessed data"],"metadata":{"id":"pRgaSOx6nl9H"}},{"cell_type":"code","source":["# Install any necessary environment if code presents errors such as downgrading:\n","#!pip install pandas==1.5.1\n"],"metadata":{"id":"I9RUQmoynlTQ","executionInfo":{"status":"ok","timestamp":1716136525019,"user_tz":360,"elapsed":494,"user":{"displayName":"Nathan Tyler","userId":"01089041167657734180"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["# Standard imports\n","import pandas as pd\n","import numpy as np\n","import pickle\n","from tensorflow.keras import layers\n","from tensorflow.keras.models import Model"],"metadata":{"id":"gcwNEVFxn2EH","executionInfo":{"status":"ok","timestamp":1716136532257,"user_tz":360,"elapsed":6687,"user":{"displayName":"Nathan Tyler","userId":"01089041167657734180"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# Connect to my Google Drive to get to Pickle File\n","from google.colab import drive\n","drive.mount(\"/content/drive\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3YpuiiCXo2IY","executionInfo":{"status":"ok","timestamp":1716136554122,"user_tz":360,"elapsed":21876,"user":{"displayName":"Nathan Tyler","userId":"01089041167657734180"}},"outputId":"73194a3a-649c-4280-df39-69f4242e983f"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["# Load pickle data and ensure correctly aligned\n","with open(\"/content/drive/My Drive/Data_CNN_Ready.pkl\", \"rb\") as file:\n","    data = pickle.load(file)"],"metadata":{"id":"6zUn7x0Yo_Tw","executionInfo":{"status":"ok","timestamp":1716136568863,"user_tz":360,"elapsed":14745,"user":{"displayName":"Nathan Tyler","userId":"01089041167657734180"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# Seperate pickled data into stucture ready for modeling\n","# Note: I am removing the \"scaled\" nomenclature used in the previously file--as I often forget that.\n","X_cat_train = np.array(data[0])\n","X_cat_test = np.array(data[1])\n","X_img_train = np.array(data[2])\n","X_img_test = np.array(data[3])\n","Y_train = np.array(data[4])\n","Y_test = np.array(data[5])"],"metadata":{"id":"K1gfvC5bqEGC","executionInfo":{"status":"ok","timestamp":1716136568864,"user_tz":360,"elapsed":17,"user":{"displayName":"Nathan Tyler","userId":"01089041167657734180"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# Verify these should now be good to send into models.\n","print(X_cat_train.shape)\n","print(X_img_train.shape)\n","print(Y_train.shape)\n","print(X_cat_test.shape)\n","print(X_img_test.shape)\n","print(Y_test.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"duSCSu4uHhyL","executionInfo":{"status":"ok","timestamp":1716136568864,"user_tz":360,"elapsed":14,"user":{"displayName":"Nathan Tyler","userId":"01089041167657734180"}},"outputId":"edbf662b-52e6-40ff-96f0-514593304e65"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["(2507, 3)\n","(2507, 256, 256, 1)\n","(2507, 15)\n","(836, 3)\n","(836, 256, 256, 1)\n","(836, 15)\n"]}]},{"cell_type":"code","source":["# Define Model (MLP) for categorical/numerical data portion\n","cat_input = layers.Input(shape=(3, ), name='cat_input')\n","\n","cat_h1 = layers.Dense(30, activation=\"relu\")(cat_input)\n","cat_h2 = layers.Dense(15, activation=\"relu\")(cat_h1)\n","\n","# we won't use an standard output layer yet as we will combine this with the image data\n","cat_model = Model(inputs=cat_input, outputs=cat_h2)"],"metadata":{"id":"DOOhpngkq1Jw","executionInfo":{"status":"ok","timestamp":1716136570070,"user_tz":360,"elapsed":1219,"user":{"displayName":"Nathan Tyler","userId":"01089041167657734180"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# Define Model (CNN) for image data portion\n","## CNN Model is based on code by pyimagesearch.com\n","img_input = layers.Input(shape=(256, 256, 1), name=\"img_input\")\n","\n","img_conv1 = layers.Conv2D(16, (3, 3), activation=\"relu\")(img_input)\n","img_bn1 = layers.BatchNormalization()(img_conv1)\n","img_mp1 = layers.MaxPooling2D((2, 2))(img_bn1)\n","img_conv2 = layers.Conv2D(32, (3, 3), activation=\"relu\")(img_mp1)\n","img_bn2 = layers.BatchNormalization()(img_conv2)\n","img_mp2 = layers.MaxPooling2D((2, 2))(img_bn2)\n","img_conv3 = layers.Conv2D(64, (3, 3), activation=\"relu\")(img_mp2)\n","img_bn3 = layers.BatchNormalization()(img_conv3)\n","img_mp3 = layers.MaxPooling2D((2, 2))(img_bn3)\n","img_flat = layers.Flatten()(img_mp3)\n","img_dense = layers.Dense(16, activation=\"relu\")(img_flat)\n","img_bn4 = layers.BatchNormalization()(img_dense)\n","img_drop = layers.Dropout(0.5)(img_bn4)\n","# final dense layer matches output of MLP model\n","img_match = layers.Dense(15, activation=\"relu\")(img_drop)\n","\n","img_model = Model(inputs=img_input, outputs=img_match)"],"metadata":{"id":"hm7Og3R8wqgs","executionInfo":{"status":"ok","timestamp":1716136570071,"user_tz":360,"elapsed":7,"user":{"displayName":"Nathan Tyler","userId":"01089041167657734180"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["# Now combine these two models for a final output\n","combined_input = layers.concatenate([cat_model.output, img_model.output])\n","combined_h1 = layers.Dense(15, activation=\"relu\")(combined_input)\n","# using sigmoid to predictd each of 14 possible outcomes which are not mutually exclusive (and 1 technically is)\n","final_out = layers.Dense(15, activation=\"sigmoid\")(combined_h1)\n","\n","mixed_model = Model(inputs=[cat_model.input, img_model.input], outputs=final_out)"],"metadata":{"id":"dZ2hI4xA2iC6","executionInfo":{"status":"ok","timestamp":1716136570071,"user_tz":360,"elapsed":6,"user":{"displayName":"Nathan Tyler","userId":"01089041167657734180"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["# Now fit and train the model\n","mixed_model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n","mixed_model.fit(x=[X_cat_train, X_img_train], y=Y_train, epochs=50, validation_split=0.2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l-8LufiI49ad","executionInfo":{"status":"ok","timestamp":1716137196054,"user_tz":360,"elapsed":625988,"user":{"displayName":"Nathan Tyler","userId":"01089041167657734180"}},"outputId":"b8bab40f-80a5-4c4a-da75-7bb3a5fc0fa8"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/200\n","63/63 [==============================] - 16s 80ms/step - loss: 0.5239 - accuracy: 0.0838 - val_loss: 0.4704 - val_accuracy: 0.0598\n","Epoch 2/200\n","63/63 [==============================] - 3s 47ms/step - loss: 0.3936 - accuracy: 0.1112 - val_loss: 0.3952 - val_accuracy: 0.0697\n","Epoch 3/200\n","63/63 [==============================] - 3s 44ms/step - loss: 0.3734 - accuracy: 0.1127 - val_loss: 0.3881 - val_accuracy: 0.1155\n","Epoch 4/200\n","63/63 [==============================] - 3s 48ms/step - loss: 0.3662 - accuracy: 0.1187 - val_loss: 0.3841 - val_accuracy: 0.0677\n","Epoch 5/200\n","63/63 [==============================] - 3s 44ms/step - loss: 0.3616 - accuracy: 0.1227 - val_loss: 0.3823 - val_accuracy: 0.1036\n","Epoch 6/200\n","63/63 [==============================] - 3s 49ms/step - loss: 0.3612 - accuracy: 0.1122 - val_loss: 0.3776 - val_accuracy: 0.0637\n","Epoch 7/200\n","63/63 [==============================] - 3s 48ms/step - loss: 0.3596 - accuracy: 0.1187 - val_loss: 0.3709 - val_accuracy: 0.0896\n","Epoch 8/200\n","63/63 [==============================] - 3s 47ms/step - loss: 0.3545 - accuracy: 0.1302 - val_loss: 0.3751 - val_accuracy: 0.1056\n","Epoch 9/200\n","63/63 [==============================] - 3s 46ms/step - loss: 0.3508 - accuracy: 0.1252 - val_loss: 0.3731 - val_accuracy: 0.0996\n","Epoch 10/200\n","63/63 [==============================] - 3s 45ms/step - loss: 0.3477 - accuracy: 0.1332 - val_loss: 0.3710 - val_accuracy: 0.1116\n","Epoch 11/200\n","63/63 [==============================] - 3s 50ms/step - loss: 0.3467 - accuracy: 0.1377 - val_loss: 0.3703 - val_accuracy: 0.1056\n","Epoch 12/200\n","63/63 [==============================] - 3s 49ms/step - loss: 0.3424 - accuracy: 0.1591 - val_loss: 0.3840 - val_accuracy: 0.0817\n","Epoch 13/200\n","63/63 [==============================] - 3s 45ms/step - loss: 0.3374 - accuracy: 0.1666 - val_loss: 0.3698 - val_accuracy: 0.0896\n","Epoch 14/200\n","63/63 [==============================] - 3s 45ms/step - loss: 0.3351 - accuracy: 0.1726 - val_loss: 0.3752 - val_accuracy: 0.0956\n","Epoch 15/200\n","63/63 [==============================] - 3s 48ms/step - loss: 0.3285 - accuracy: 0.1945 - val_loss: 0.3796 - val_accuracy: 0.1016\n","Epoch 16/200\n","63/63 [==============================] - 3s 52ms/step - loss: 0.3246 - accuracy: 0.2020 - val_loss: 0.3770 - val_accuracy: 0.0996\n","Epoch 17/200\n","63/63 [==============================] - 3s 48ms/step - loss: 0.3184 - accuracy: 0.2209 - val_loss: 0.3923 - val_accuracy: 0.1036\n","Epoch 18/200\n","63/63 [==============================] - 3s 48ms/step - loss: 0.3099 - accuracy: 0.2369 - val_loss: 0.4121 - val_accuracy: 0.0697\n","Epoch 19/200\n","63/63 [==============================] - 3s 47ms/step - loss: 0.3063 - accuracy: 0.2554 - val_loss: 0.3841 - val_accuracy: 0.1096\n","Epoch 20/200\n","63/63 [==============================] - 3s 51ms/step - loss: 0.3026 - accuracy: 0.2628 - val_loss: 0.4026 - val_accuracy: 0.1474\n","Epoch 21/200\n","63/63 [==============================] - 3s 48ms/step - loss: 0.2938 - accuracy: 0.2988 - val_loss: 0.3885 - val_accuracy: 0.1355\n","Epoch 22/200\n","63/63 [==============================] - 3s 46ms/step - loss: 0.2839 - accuracy: 0.3157 - val_loss: 0.3861 - val_accuracy: 0.1275\n","Epoch 23/200\n","63/63 [==============================] - 3s 48ms/step - loss: 0.2767 - accuracy: 0.3382 - val_loss: 0.3931 - val_accuracy: 0.1554\n","Epoch 24/200\n","63/63 [==============================] - 3s 46ms/step - loss: 0.2727 - accuracy: 0.3446 - val_loss: 0.4039 - val_accuracy: 0.1494\n","Epoch 25/200\n","63/63 [==============================] - 3s 52ms/step - loss: 0.2669 - accuracy: 0.3591 - val_loss: 0.4333 - val_accuracy: 0.1016\n","Epoch 26/200\n","63/63 [==============================] - 3s 47ms/step - loss: 0.2620 - accuracy: 0.3756 - val_loss: 0.4217 - val_accuracy: 0.1275\n","Epoch 27/200\n","63/63 [==============================] - 3s 48ms/step - loss: 0.2578 - accuracy: 0.3716 - val_loss: 0.4123 - val_accuracy: 0.1275\n","Epoch 28/200\n","63/63 [==============================] - 3s 46ms/step - loss: 0.2546 - accuracy: 0.3731 - val_loss: 0.4210 - val_accuracy: 0.1135\n","Epoch 29/200\n","63/63 [==============================] - 3s 47ms/step - loss: 0.2473 - accuracy: 0.3905 - val_loss: 0.4052 - val_accuracy: 0.1414\n","Epoch 30/200\n","63/63 [==============================] - 3s 49ms/step - loss: 0.2422 - accuracy: 0.4145 - val_loss: 0.4267 - val_accuracy: 0.1335\n","Epoch 31/200\n","63/63 [==============================] - 3s 47ms/step - loss: 0.2383 - accuracy: 0.4399 - val_loss: 0.4105 - val_accuracy: 0.1375\n","Epoch 32/200\n","63/63 [==============================] - 3s 45ms/step - loss: 0.2308 - accuracy: 0.4294 - val_loss: 0.4389 - val_accuracy: 0.1355\n","Epoch 33/200\n","63/63 [==============================] - 3s 45ms/step - loss: 0.2277 - accuracy: 0.4304 - val_loss: 0.4226 - val_accuracy: 0.1414\n","Epoch 34/200\n","63/63 [==============================] - 3s 48ms/step - loss: 0.2268 - accuracy: 0.4200 - val_loss: 0.4181 - val_accuracy: 0.1474\n","Epoch 35/200\n","63/63 [==============================] - 3s 50ms/step - loss: 0.2228 - accuracy: 0.4504 - val_loss: 0.4120 - val_accuracy: 0.1773\n","Epoch 36/200\n","63/63 [==============================] - 3s 45ms/step - loss: 0.2194 - accuracy: 0.4569 - val_loss: 0.4315 - val_accuracy: 0.1434\n","Epoch 37/200\n","63/63 [==============================] - 3s 45ms/step - loss: 0.2184 - accuracy: 0.4474 - val_loss: 0.4183 - val_accuracy: 0.1414\n","Epoch 38/200\n","63/63 [==============================] - 3s 48ms/step - loss: 0.2132 - accuracy: 0.4678 - val_loss: 0.4738 - val_accuracy: 0.0916\n","Epoch 39/200\n","63/63 [==============================] - 3s 54ms/step - loss: 0.2099 - accuracy: 0.4688 - val_loss: 0.4515 - val_accuracy: 0.1195\n","Epoch 40/200\n","63/63 [==============================] - 3s 53ms/step - loss: 0.2084 - accuracy: 0.4773 - val_loss: 0.4256 - val_accuracy: 0.1594\n","Epoch 41/200\n","63/63 [==============================] - 3s 48ms/step - loss: 0.2085 - accuracy: 0.4688 - val_loss: 0.4538 - val_accuracy: 0.1673\n","Epoch 42/200\n","63/63 [==============================] - 3s 47ms/step - loss: 0.2025 - accuracy: 0.4843 - val_loss: 0.4325 - val_accuracy: 0.1375\n","Epoch 43/200\n","63/63 [==============================] - 3s 48ms/step - loss: 0.2023 - accuracy: 0.4853 - val_loss: 0.4438 - val_accuracy: 0.1235\n","Epoch 44/200\n","63/63 [==============================] - 3s 49ms/step - loss: 0.2026 - accuracy: 0.4753 - val_loss: 0.4523 - val_accuracy: 0.1793\n","Epoch 45/200\n","63/63 [==============================] - 3s 50ms/step - loss: 0.1981 - accuracy: 0.4803 - val_loss: 0.4520 - val_accuracy: 0.1375\n","Epoch 46/200\n","63/63 [==============================] - 3s 45ms/step - loss: 0.1974 - accuracy: 0.4843 - val_loss: 0.4469 - val_accuracy: 0.1454\n","Epoch 47/200\n","63/63 [==============================] - 3s 45ms/step - loss: 0.1927 - accuracy: 0.5002 - val_loss: 0.4703 - val_accuracy: 0.1036\n","Epoch 48/200\n","63/63 [==============================] - 3s 45ms/step - loss: 0.1893 - accuracy: 0.5057 - val_loss: 0.4609 - val_accuracy: 0.1295\n","Epoch 49/200\n","63/63 [==============================] - 3s 50ms/step - loss: 0.1886 - accuracy: 0.5152 - val_loss: 0.4650 - val_accuracy: 0.1096\n","Epoch 50/200\n","63/63 [==============================] - 3s 49ms/step - loss: 0.1872 - accuracy: 0.4918 - val_loss: 0.4818 - val_accuracy: 0.1076\n","Epoch 51/200\n","63/63 [==============================] - 3s 47ms/step - loss: 0.1874 - accuracy: 0.5062 - val_loss: 0.4591 - val_accuracy: 0.1534\n","Epoch 52/200\n","63/63 [==============================] - 3s 46ms/step - loss: 0.1866 - accuracy: 0.5147 - val_loss: 0.4552 - val_accuracy: 0.1474\n","Epoch 53/200\n","63/63 [==============================] - 3s 47ms/step - loss: 0.1804 - accuracy: 0.5062 - val_loss: 0.4554 - val_accuracy: 0.1375\n","Epoch 54/200\n","63/63 [==============================] - 3s 52ms/step - loss: 0.1827 - accuracy: 0.5207 - val_loss: 0.4755 - val_accuracy: 0.1235\n","Epoch 55/200\n","63/63 [==============================] - 3s 46ms/step - loss: 0.1799 - accuracy: 0.5107 - val_loss: 0.4930 - val_accuracy: 0.1116\n","Epoch 56/200\n","63/63 [==============================] - 3s 48ms/step - loss: 0.1810 - accuracy: 0.5107 - val_loss: 0.4669 - val_accuracy: 0.1255\n","Epoch 57/200\n","63/63 [==============================] - 3s 47ms/step - loss: 0.1750 - accuracy: 0.5252 - val_loss: 0.4751 - val_accuracy: 0.1394\n","Epoch 58/200\n","63/63 [==============================] - 3s 49ms/step - loss: 0.1761 - accuracy: 0.5222 - val_loss: 0.4905 - val_accuracy: 0.1135\n","Epoch 59/200\n","63/63 [==============================] - 3s 49ms/step - loss: 0.1720 - accuracy: 0.5232 - val_loss: 0.4622 - val_accuracy: 0.1434\n","Epoch 60/200\n","63/63 [==============================] - 3s 47ms/step - loss: 0.1730 - accuracy: 0.5426 - val_loss: 0.5082 - val_accuracy: 0.1175\n","Epoch 61/200\n","63/63 [==============================] - 3s 45ms/step - loss: 0.1718 - accuracy: 0.5262 - val_loss: 0.4794 - val_accuracy: 0.1574\n","Epoch 62/200\n","63/63 [==============================] - 3s 45ms/step - loss: 0.1727 - accuracy: 0.5302 - val_loss: 0.4607 - val_accuracy: 0.1594\n","Epoch 63/200\n","63/63 [==============================] - 3s 50ms/step - loss: 0.1666 - accuracy: 0.5446 - val_loss: 0.4803 - val_accuracy: 0.1255\n","Epoch 64/200\n","63/63 [==============================] - 3s 47ms/step - loss: 0.1660 - accuracy: 0.5451 - val_loss: 0.4755 - val_accuracy: 0.1335\n","Epoch 65/200\n","63/63 [==============================] - 3s 46ms/step - loss: 0.1660 - accuracy: 0.5302 - val_loss: 0.4912 - val_accuracy: 0.1394\n","Epoch 66/200\n","63/63 [==============================] - 3s 46ms/step - loss: 0.1646 - accuracy: 0.5526 - val_loss: 0.4794 - val_accuracy: 0.1315\n","Epoch 67/200\n","63/63 [==============================] - 3s 46ms/step - loss: 0.1658 - accuracy: 0.5401 - val_loss: 0.4788 - val_accuracy: 0.1454\n","Epoch 68/200\n","63/63 [==============================] - 3s 51ms/step - loss: 0.1631 - accuracy: 0.5237 - val_loss: 0.5167 - val_accuracy: 0.1952\n","Epoch 69/200\n","63/63 [==============================] - 3s 47ms/step - loss: 0.1629 - accuracy: 0.5441 - val_loss: 0.5003 - val_accuracy: 0.1076\n","Epoch 70/200\n","63/63 [==============================] - 3s 46ms/step - loss: 0.1672 - accuracy: 0.5327 - val_loss: 0.4808 - val_accuracy: 0.1355\n","Epoch 71/200\n","63/63 [==============================] - 3s 45ms/step - loss: 0.1615 - accuracy: 0.5431 - val_loss: 0.4892 - val_accuracy: 0.1155\n","Epoch 72/200\n","63/63 [==============================] - 3s 47ms/step - loss: 0.1608 - accuracy: 0.5486 - val_loss: 0.4827 - val_accuracy: 0.1434\n","Epoch 73/200\n","63/63 [==============================] - 3s 51ms/step - loss: 0.1609 - accuracy: 0.5466 - val_loss: 0.4851 - val_accuracy: 0.1036\n","Epoch 74/200\n","63/63 [==============================] - 3s 47ms/step - loss: 0.1630 - accuracy: 0.5267 - val_loss: 0.5038 - val_accuracy: 0.1494\n","Epoch 75/200\n","63/63 [==============================] - 3s 45ms/step - loss: 0.1598 - accuracy: 0.5347 - val_loss: 0.4810 - val_accuracy: 0.1414\n","Epoch 76/200\n","63/63 [==============================] - 3s 47ms/step - loss: 0.1577 - accuracy: 0.5387 - val_loss: 0.4920 - val_accuracy: 0.1275\n","Epoch 77/200\n","63/63 [==============================] - 3s 50ms/step - loss: 0.1569 - accuracy: 0.5521 - val_loss: 0.4923 - val_accuracy: 0.1534\n","Epoch 78/200\n","63/63 [==============================] - 3s 51ms/step - loss: 0.1570 - accuracy: 0.5666 - val_loss: 0.4990 - val_accuracy: 0.1394\n","Epoch 79/200\n","63/63 [==============================] - 3s 47ms/step - loss: 0.1531 - accuracy: 0.5521 - val_loss: 0.4922 - val_accuracy: 0.1215\n","Epoch 80/200\n","63/63 [==============================] - 3s 45ms/step - loss: 0.1529 - accuracy: 0.5471 - val_loss: 0.4877 - val_accuracy: 0.1175\n","Epoch 81/200\n","63/63 [==============================] - 3s 46ms/step - loss: 0.1562 - accuracy: 0.5461 - val_loss: 0.5084 - val_accuracy: 0.1155\n","Epoch 82/200\n","63/63 [==============================] - 3s 50ms/step - loss: 0.1557 - accuracy: 0.5571 - val_loss: 0.5144 - val_accuracy: 0.1414\n","Epoch 83/200\n","63/63 [==============================] - 3s 49ms/step - loss: 0.1511 - accuracy: 0.5631 - val_loss: 0.5045 - val_accuracy: 0.1235\n","Epoch 84/200\n","63/63 [==============================] - 3s 47ms/step - loss: 0.1552 - accuracy: 0.5486 - val_loss: 0.4758 - val_accuracy: 0.1633\n","Epoch 85/200\n","63/63 [==============================] - 3s 47ms/step - loss: 0.1497 - accuracy: 0.5506 - val_loss: 0.4978 - val_accuracy: 0.1394\n","Epoch 86/200\n","63/63 [==============================] - 3s 49ms/step - loss: 0.1481 - accuracy: 0.5561 - val_loss: 0.4935 - val_accuracy: 0.1175\n","Epoch 87/200\n","63/63 [==============================] - 3s 49ms/step - loss: 0.1496 - accuracy: 0.5546 - val_loss: 0.5121 - val_accuracy: 0.1335\n","Epoch 88/200\n","63/63 [==============================] - 3s 48ms/step - loss: 0.1475 - accuracy: 0.5411 - val_loss: 0.5038 - val_accuracy: 0.1315\n","Epoch 89/200\n","63/63 [==============================] - 3s 46ms/step - loss: 0.1482 - accuracy: 0.5511 - val_loss: 0.5178 - val_accuracy: 0.1434\n","Epoch 90/200\n","63/63 [==============================] - 3s 46ms/step - loss: 0.1483 - accuracy: 0.5456 - val_loss: 0.5233 - val_accuracy: 0.1195\n","Epoch 91/200\n","63/63 [==============================] - 3s 51ms/step - loss: 0.1487 - accuracy: 0.5496 - val_loss: 0.5423 - val_accuracy: 0.1175\n","Epoch 92/200\n","63/63 [==============================] - 3s 50ms/step - loss: 0.1497 - accuracy: 0.5481 - val_loss: 0.4934 - val_accuracy: 0.1454\n","Epoch 93/200\n","63/63 [==============================] - 3s 46ms/step - loss: 0.1500 - accuracy: 0.5601 - val_loss: 0.5289 - val_accuracy: 0.1315\n","Epoch 94/200\n","63/63 [==============================] - 3s 46ms/step - loss: 0.1487 - accuracy: 0.5506 - val_loss: 0.5323 - val_accuracy: 0.1175\n","Epoch 95/200\n","63/63 [==============================] - 3s 48ms/step - loss: 0.1410 - accuracy: 0.5526 - val_loss: 0.5106 - val_accuracy: 0.1335\n","Epoch 96/200\n","63/63 [==============================] - 3s 52ms/step - loss: 0.1436 - accuracy: 0.5616 - val_loss: 0.4986 - val_accuracy: 0.1375\n","Epoch 97/200\n","63/63 [==============================] - 3s 49ms/step - loss: 0.1435 - accuracy: 0.5536 - val_loss: 0.5104 - val_accuracy: 0.1355\n","Epoch 98/200\n","63/63 [==============================] - 3s 45ms/step - loss: 0.1439 - accuracy: 0.5581 - val_loss: 0.5070 - val_accuracy: 0.1514\n","Epoch 99/200\n","63/63 [==============================] - 3s 48ms/step - loss: 0.1447 - accuracy: 0.5621 - val_loss: 0.5234 - val_accuracy: 0.1235\n","Epoch 100/200\n","63/63 [==============================] - 3s 49ms/step - loss: 0.1382 - accuracy: 0.5546 - val_loss: 0.5365 - val_accuracy: 0.1434\n","Epoch 101/200\n","63/63 [==============================] - 3s 48ms/step - loss: 0.1421 - accuracy: 0.5681 - val_loss: 0.5089 - val_accuracy: 0.1255\n","Epoch 102/200\n","63/63 [==============================] - 3s 46ms/step - loss: 0.1462 - accuracy: 0.5616 - val_loss: 0.5056 - val_accuracy: 0.1434\n","Epoch 103/200\n","63/63 [==============================] - 3s 48ms/step - loss: 0.1469 - accuracy: 0.5761 - val_loss: 0.4862 - val_accuracy: 0.1235\n","Epoch 104/200\n","63/63 [==============================] - 3s 46ms/step - loss: 0.1421 - accuracy: 0.5691 - val_loss: 0.5271 - val_accuracy: 0.1195\n","Epoch 105/200\n","63/63 [==============================] - 3s 48ms/step - loss: 0.1433 - accuracy: 0.5536 - val_loss: 0.5246 - val_accuracy: 0.1275\n","Epoch 106/200\n","63/63 [==============================] - 3s 48ms/step - loss: 0.1431 - accuracy: 0.5636 - val_loss: 0.5314 - val_accuracy: 0.1335\n","Epoch 107/200\n","63/63 [==============================] - 3s 46ms/step - loss: 0.1408 - accuracy: 0.5616 - val_loss: 0.5408 - val_accuracy: 0.1394\n","Epoch 108/200\n","63/63 [==============================] - 3s 45ms/step - loss: 0.1390 - accuracy: 0.5611 - val_loss: 0.5222 - val_accuracy: 0.1434\n","Epoch 109/200\n","63/63 [==============================] - 3s 46ms/step - loss: 0.1369 - accuracy: 0.5646 - val_loss: 0.5467 - val_accuracy: 0.1295\n","Epoch 110/200\n","63/63 [==============================] - 3s 49ms/step - loss: 0.1408 - accuracy: 0.5636 - val_loss: 0.5342 - val_accuracy: 0.1414\n","Epoch 111/200\n","63/63 [==============================] - 3s 47ms/step - loss: 0.1388 - accuracy: 0.5546 - val_loss: 0.5533 - val_accuracy: 0.1434\n","Epoch 112/200\n","63/63 [==============================] - 3s 47ms/step - loss: 0.1399 - accuracy: 0.5441 - val_loss: 0.5202 - val_accuracy: 0.1275\n","Epoch 113/200\n","63/63 [==============================] - 3s 46ms/step - loss: 0.1417 - accuracy: 0.5451 - val_loss: 0.5080 - val_accuracy: 0.1255\n","Epoch 114/200\n","63/63 [==============================] - 3s 48ms/step - loss: 0.1401 - accuracy: 0.5611 - val_loss: 0.5203 - val_accuracy: 0.1096\n","Epoch 115/200\n","63/63 [==============================] - 3s 51ms/step - loss: 0.1425 - accuracy: 0.5521 - val_loss: 0.5175 - val_accuracy: 0.1155\n","Epoch 116/200\n","63/63 [==============================] - 3s 46ms/step - loss: 0.1405 - accuracy: 0.5751 - val_loss: 0.5275 - val_accuracy: 0.1355\n","Epoch 117/200\n","63/63 [==============================] - 3s 47ms/step - loss: 0.1366 - accuracy: 0.5716 - val_loss: 0.5142 - val_accuracy: 0.1414\n","Epoch 118/200\n","63/63 [==============================] - 3s 46ms/step - loss: 0.1384 - accuracy: 0.5746 - val_loss: 0.5069 - val_accuracy: 0.1375\n","Epoch 119/200\n","63/63 [==============================] - 3s 48ms/step - loss: 0.1359 - accuracy: 0.5646 - val_loss: 0.5074 - val_accuracy: 0.1215\n","Epoch 120/200\n","63/63 [==============================] - 3s 49ms/step - loss: 0.1391 - accuracy: 0.5486 - val_loss: 0.5304 - val_accuracy: 0.1215\n","Epoch 121/200\n","63/63 [==============================] - 3s 46ms/step - loss: 0.1370 - accuracy: 0.5606 - val_loss: 0.5196 - val_accuracy: 0.1394\n","Epoch 122/200\n","63/63 [==============================] - 3s 46ms/step - loss: 0.1341 - accuracy: 0.5686 - val_loss: 0.5237 - val_accuracy: 0.1096\n","Epoch 123/200\n","63/63 [==============================] - 3s 48ms/step - loss: 0.1356 - accuracy: 0.5591 - val_loss: 0.5250 - val_accuracy: 0.1295\n","Epoch 124/200\n","63/63 [==============================] - 3s 48ms/step - loss: 0.1364 - accuracy: 0.5771 - val_loss: 0.5524 - val_accuracy: 0.1275\n","Epoch 125/200\n","63/63 [==============================] - 3s 48ms/step - loss: 0.1376 - accuracy: 0.5781 - val_loss: 0.5652 - val_accuracy: 0.1315\n","Epoch 126/200\n","63/63 [==============================] - 3s 46ms/step - loss: 0.1367 - accuracy: 0.5501 - val_loss: 0.5260 - val_accuracy: 0.1036\n","Epoch 127/200\n","63/63 [==============================] - 3s 46ms/step - loss: 0.1336 - accuracy: 0.5601 - val_loss: 0.5377 - val_accuracy: 0.1175\n","Epoch 128/200\n","63/63 [==============================] - 3s 48ms/step - loss: 0.1343 - accuracy: 0.5606 - val_loss: 0.5533 - val_accuracy: 0.1295\n","Epoch 129/200\n","63/63 [==============================] - 3s 51ms/step - loss: 0.1307 - accuracy: 0.5686 - val_loss: 0.5180 - val_accuracy: 0.1355\n","Epoch 130/200\n","63/63 [==============================] - 3s 47ms/step - loss: 0.1361 - accuracy: 0.5621 - val_loss: 0.5421 - val_accuracy: 0.1315\n","Epoch 131/200\n","63/63 [==============================] - 3s 46ms/step - loss: 0.1309 - accuracy: 0.5756 - val_loss: 0.5209 - val_accuracy: 0.1295\n","Epoch 132/200\n","63/63 [==============================] - 3s 48ms/step - loss: 0.1359 - accuracy: 0.5696 - val_loss: 0.5340 - val_accuracy: 0.1275\n","Epoch 133/200\n","63/63 [==============================] - 3s 50ms/step - loss: 0.1309 - accuracy: 0.5626 - val_loss: 0.5305 - val_accuracy: 0.1375\n","Epoch 134/200\n","63/63 [==============================] - 3s 55ms/step - loss: 0.1317 - accuracy: 0.5791 - val_loss: 0.5477 - val_accuracy: 0.1155\n","Epoch 135/200\n","63/63 [==============================] - 3s 50ms/step - loss: 0.1323 - accuracy: 0.5641 - val_loss: 0.5240 - val_accuracy: 0.1255\n","Epoch 136/200\n","63/63 [==============================] - 3s 47ms/step - loss: 0.1328 - accuracy: 0.5800 - val_loss: 0.5455 - val_accuracy: 0.1215\n","Epoch 137/200\n","63/63 [==============================] - 3s 46ms/step - loss: 0.1332 - accuracy: 0.5661 - val_loss: 0.5149 - val_accuracy: 0.1195\n","Epoch 138/200\n","63/63 [==============================] - 3s 46ms/step - loss: 0.1300 - accuracy: 0.5601 - val_loss: 0.5388 - val_accuracy: 0.1414\n","Epoch 139/200\n","63/63 [==============================] - 3s 51ms/step - loss: 0.1356 - accuracy: 0.5621 - val_loss: 0.5308 - val_accuracy: 0.1474\n","Epoch 140/200\n","63/63 [==============================] - 3s 46ms/step - loss: 0.1292 - accuracy: 0.5711 - val_loss: 0.5470 - val_accuracy: 0.1275\n","Epoch 141/200\n","63/63 [==============================] - 3s 48ms/step - loss: 0.1293 - accuracy: 0.5681 - val_loss: 0.5255 - val_accuracy: 0.1554\n","Epoch 142/200\n","63/63 [==============================] - 3s 46ms/step - loss: 0.1293 - accuracy: 0.5751 - val_loss: 0.5568 - val_accuracy: 0.1554\n","Epoch 143/200\n","63/63 [==============================] - 3s 49ms/step - loss: 0.1292 - accuracy: 0.5786 - val_loss: 0.5369 - val_accuracy: 0.1375\n","Epoch 144/200\n","63/63 [==============================] - 3s 49ms/step - loss: 0.1311 - accuracy: 0.5576 - val_loss: 0.5189 - val_accuracy: 0.1434\n","Epoch 145/200\n","63/63 [==============================] - 3s 46ms/step - loss: 0.1298 - accuracy: 0.5681 - val_loss: 0.5275 - val_accuracy: 0.1394\n","Epoch 146/200\n","63/63 [==============================] - 3s 48ms/step - loss: 0.1316 - accuracy: 0.5810 - val_loss: 0.5726 - val_accuracy: 0.1394\n","Epoch 147/200\n","63/63 [==============================] - 3s 48ms/step - loss: 0.1326 - accuracy: 0.5706 - val_loss: 0.5249 - val_accuracy: 0.1355\n","Epoch 148/200\n","63/63 [==============================] - 3s 49ms/step - loss: 0.1308 - accuracy: 0.5805 - val_loss: 0.5255 - val_accuracy: 0.1375\n","Epoch 149/200\n","63/63 [==============================] - 3s 50ms/step - loss: 0.1249 - accuracy: 0.5800 - val_loss: 0.5336 - val_accuracy: 0.1135\n","Epoch 150/200\n","63/63 [==============================] - 3s 48ms/step - loss: 0.1325 - accuracy: 0.5471 - val_loss: 0.5631 - val_accuracy: 0.1215\n","Epoch 151/200\n","63/63 [==============================] - 3s 46ms/step - loss: 0.1304 - accuracy: 0.5546 - val_loss: 0.5314 - val_accuracy: 0.1295\n","Epoch 152/200\n","63/63 [==============================] - 3s 48ms/step - loss: 0.1271 - accuracy: 0.5746 - val_loss: 0.5659 - val_accuracy: 0.1295\n","Epoch 153/200\n","63/63 [==============================] - 3s 50ms/step - loss: 0.1288 - accuracy: 0.5651 - val_loss: 0.5240 - val_accuracy: 0.1355\n","Epoch 154/200\n","63/63 [==============================] - 3s 46ms/step - loss: 0.1289 - accuracy: 0.5461 - val_loss: 0.5286 - val_accuracy: 0.1315\n","Epoch 155/200\n","63/63 [==============================] - 3s 45ms/step - loss: 0.1273 - accuracy: 0.5631 - val_loss: 0.5476 - val_accuracy: 0.1614\n","Epoch 156/200\n","63/63 [==============================] - 3s 45ms/step - loss: 0.1281 - accuracy: 0.5631 - val_loss: 0.5480 - val_accuracy: 0.1574\n","Epoch 157/200\n","63/63 [==============================] - 3s 47ms/step - loss: 0.1258 - accuracy: 0.5786 - val_loss: 0.5272 - val_accuracy: 0.1255\n","Epoch 158/200\n","63/63 [==============================] - 3s 50ms/step - loss: 0.1302 - accuracy: 0.5761 - val_loss: 0.5758 - val_accuracy: 0.1335\n","Epoch 159/200\n","63/63 [==============================] - 3s 46ms/step - loss: 0.1318 - accuracy: 0.5756 - val_loss: 0.5587 - val_accuracy: 0.1335\n","Epoch 160/200\n","63/63 [==============================] - 3s 47ms/step - loss: 0.1279 - accuracy: 0.5706 - val_loss: 0.5607 - val_accuracy: 0.1514\n","Epoch 161/200\n","63/63 [==============================] - 3s 45ms/step - loss: 0.1262 - accuracy: 0.5716 - val_loss: 0.5427 - val_accuracy: 0.1335\n","Epoch 162/200\n","63/63 [==============================] - 3s 49ms/step - loss: 0.1281 - accuracy: 0.5546 - val_loss: 0.5331 - val_accuracy: 0.1295\n","Epoch 163/200\n","63/63 [==============================] - 3s 50ms/step - loss: 0.1261 - accuracy: 0.5865 - val_loss: 0.5353 - val_accuracy: 0.1375\n","Epoch 164/200\n","63/63 [==============================] - 3s 45ms/step - loss: 0.1268 - accuracy: 0.5696 - val_loss: 0.5397 - val_accuracy: 0.1135\n","Epoch 165/200\n","63/63 [==============================] - 3s 45ms/step - loss: 0.1235 - accuracy: 0.5586 - val_loss: 0.5338 - val_accuracy: 0.1255\n","Epoch 166/200\n","63/63 [==============================] - 3s 47ms/step - loss: 0.1316 - accuracy: 0.5661 - val_loss: 0.5557 - val_accuracy: 0.1235\n","Epoch 167/200\n","63/63 [==============================] - 3s 48ms/step - loss: 0.1268 - accuracy: 0.5711 - val_loss: 0.5320 - val_accuracy: 0.1335\n","Epoch 168/200\n","63/63 [==============================] - 3s 47ms/step - loss: 0.1291 - accuracy: 0.5646 - val_loss: 0.5260 - val_accuracy: 0.1574\n","Epoch 169/200\n","63/63 [==============================] - 3s 47ms/step - loss: 0.1272 - accuracy: 0.5810 - val_loss: 0.5583 - val_accuracy: 0.1494\n","Epoch 170/200\n","63/63 [==============================] - 3s 47ms/step - loss: 0.1262 - accuracy: 0.5736 - val_loss: 0.5169 - val_accuracy: 0.1474\n","Epoch 171/200\n","63/63 [==============================] - 3s 46ms/step - loss: 0.1268 - accuracy: 0.5656 - val_loss: 0.5337 - val_accuracy: 0.1394\n","Epoch 172/200\n","63/63 [==============================] - 3s 51ms/step - loss: 0.1250 - accuracy: 0.5805 - val_loss: 0.5722 - val_accuracy: 0.1414\n","Epoch 173/200\n","63/63 [==============================] - 3s 46ms/step - loss: 0.1243 - accuracy: 0.5746 - val_loss: 0.5514 - val_accuracy: 0.1394\n","Epoch 174/200\n","63/63 [==============================] - 3s 47ms/step - loss: 0.1249 - accuracy: 0.5626 - val_loss: 0.5511 - val_accuracy: 0.1275\n","Epoch 175/200\n","63/63 [==============================] - 3s 45ms/step - loss: 0.1261 - accuracy: 0.5786 - val_loss: 0.5459 - val_accuracy: 0.1235\n","Epoch 176/200\n","63/63 [==============================] - 3s 47ms/step - loss: 0.1229 - accuracy: 0.5820 - val_loss: 0.5351 - val_accuracy: 0.1235\n","Epoch 177/200\n","63/63 [==============================] - 3s 48ms/step - loss: 0.1314 - accuracy: 0.5486 - val_loss: 0.5185 - val_accuracy: 0.1195\n","Epoch 178/200\n","63/63 [==============================] - 3s 47ms/step - loss: 0.1272 - accuracy: 0.5571 - val_loss: 0.5228 - val_accuracy: 0.1454\n","Epoch 179/200\n","63/63 [==============================] - 3s 45ms/step - loss: 0.1235 - accuracy: 0.5830 - val_loss: 0.5655 - val_accuracy: 0.1175\n","Epoch 180/200\n","63/63 [==============================] - 3s 45ms/step - loss: 0.1238 - accuracy: 0.5716 - val_loss: 0.5587 - val_accuracy: 0.1175\n","Epoch 181/200\n","63/63 [==============================] - 3s 48ms/step - loss: 0.1252 - accuracy: 0.5696 - val_loss: 0.5566 - val_accuracy: 0.1474\n","Epoch 182/200\n","63/63 [==============================] - 3s 49ms/step - loss: 0.1250 - accuracy: 0.5880 - val_loss: 0.5493 - val_accuracy: 0.1295\n","Epoch 183/200\n","63/63 [==============================] - 3s 47ms/step - loss: 0.1248 - accuracy: 0.5711 - val_loss: 0.5555 - val_accuracy: 0.1633\n","Epoch 184/200\n","63/63 [==============================] - 3s 47ms/step - loss: 0.1282 - accuracy: 0.5611 - val_loss: 0.5365 - val_accuracy: 0.1434\n","Epoch 185/200\n","63/63 [==============================] - 3s 45ms/step - loss: 0.1273 - accuracy: 0.5721 - val_loss: 0.5534 - val_accuracy: 0.1454\n","Epoch 186/200\n","63/63 [==============================] - 3s 48ms/step - loss: 0.1256 - accuracy: 0.5646 - val_loss: 0.5433 - val_accuracy: 0.1434\n","Epoch 187/200\n","63/63 [==============================] - 3s 46ms/step - loss: 0.1272 - accuracy: 0.5810 - val_loss: 0.5472 - val_accuracy: 0.1275\n","Epoch 188/200\n","63/63 [==============================] - 3s 45ms/step - loss: 0.1254 - accuracy: 0.5716 - val_loss: 0.5676 - val_accuracy: 0.1394\n","Epoch 189/200\n","63/63 [==============================] - 3s 45ms/step - loss: 0.1251 - accuracy: 0.5591 - val_loss: 0.5500 - val_accuracy: 0.1295\n","Epoch 190/200\n","63/63 [==============================] - 3s 45ms/step - loss: 0.1222 - accuracy: 0.5736 - val_loss: 0.5224 - val_accuracy: 0.1255\n","Epoch 191/200\n","63/63 [==============================] - 3s 51ms/step - loss: 0.1203 - accuracy: 0.5706 - val_loss: 0.5328 - val_accuracy: 0.1016\n","Epoch 192/200\n","63/63 [==============================] - 3s 48ms/step - loss: 0.1260 - accuracy: 0.5781 - val_loss: 0.5430 - val_accuracy: 0.1116\n","Epoch 193/200\n","63/63 [==============================] - 3s 47ms/step - loss: 0.1221 - accuracy: 0.5776 - val_loss: 0.5383 - val_accuracy: 0.1215\n","Epoch 194/200\n","63/63 [==============================] - 3s 45ms/step - loss: 0.1231 - accuracy: 0.5681 - val_loss: 0.5329 - val_accuracy: 0.1135\n","Epoch 195/200\n","63/63 [==============================] - 3s 48ms/step - loss: 0.1256 - accuracy: 0.5825 - val_loss: 0.5524 - val_accuracy: 0.1315\n","Epoch 196/200\n","63/63 [==============================] - 3s 48ms/step - loss: 0.1216 - accuracy: 0.5636 - val_loss: 0.5347 - val_accuracy: 0.1155\n","Epoch 197/200\n","63/63 [==============================] - 3s 45ms/step - loss: 0.1271 - accuracy: 0.5691 - val_loss: 0.5609 - val_accuracy: 0.1295\n","Epoch 198/200\n","63/63 [==============================] - 3s 45ms/step - loss: 0.1214 - accuracy: 0.5651 - val_loss: 0.5695 - val_accuracy: 0.1434\n","Epoch 199/200\n","63/63 [==============================] - 3s 45ms/step - loss: 0.1264 - accuracy: 0.5666 - val_loss: 0.5503 - val_accuracy: 0.1554\n","Epoch 200/200\n","63/63 [==============================] - 3s 49ms/step - loss: 0.1237 - accuracy: 0.5731 - val_loss: 0.5804 - val_accuracy: 0.1315\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.History at 0x7a343aea7bb0>"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["# Evaluate teh model\n","eval_loss, eval_accuracy = mixed_model.evaluate([X_cat_test, X_img_test], Y_test)\n","print(f\"Loss: {eval_loss}, Accuracy: {eval_accuracy}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UAs65sSe7ey4","executionInfo":{"status":"ok","timestamp":1716137197354,"user_tz":360,"elapsed":1305,"user":{"displayName":"Nathan Tyler","userId":"01089041167657734180"}},"outputId":"40fe237b-6e71-4cdd-ca51-835ada13936b"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["27/27 [==============================] - 1s 23ms/step - loss: 0.5657 - accuracy: 0.1077\n","Loss: 0.5657050013542175, Accuracy: 0.10765550285577774\n"]}]},{"cell_type":"code","source":["# Finally save the pre-trained model for use elsewhere\n","mixed_model.save(\"/content/drive/My Drive/xrays-full.keras\")"],"metadata":{"id":"e4P6nohN8TMe","executionInfo":{"status":"ok","timestamp":1716137199301,"user_tz":360,"elapsed":1951,"user":{"displayName":"Nathan Tyler","userId":"01089041167657734180"}}},"execution_count":12,"outputs":[]}]}